const startBtn = document.getElementById('btnStart');
const stopBtn = document.getElementById('btnStop');
const statusSpan = document.getElementById('status');
const audioPlayer = document.getElementById('audioPlayer');

let audioContext;
let mediaStream;
let workletNode;
let mediaRecorder;
let chunks = [];

// Error à¤¦à¤¿à¤–à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¹à¥‡à¤²à¥à¤ªà¤° à¤«à¤‚à¤•à¥à¤¶à¤¨
function log(msg, isError = false) {
    console.log(msg);
    statusSpan.innerText = msg;
    if (isError) statusSpan.style.color = "red";
    else statusSpan.style.color = "#00f2c3"; // Greenish
}

startBtn.onclick = async () => {
    try {
        log("Starting Setup...");
        
        // 1. AudioContext à¤¬à¤¨à¤¾à¤à¤
        const AudioContext = window.AudioContext || window.webkitAudioContext;
        audioContext = new AudioContext();

        // Mobile Fix: Resume Context (à¤¬à¤¹à¥à¤¤ à¥›à¤°à¥‚à¤°à¥€)
        if (audioContext.state === 'suspended') {
            await audioContext.resume();
        }

        log("Loading AI Module...");
        try {
            await audioContext.audioWorklet.addModule('processor.js');
        } catch (e) {
            throw new Error("processor.js à¤²à¥‹à¤¡ à¤¨à¤¹à¥€à¤‚ à¤¹à¥à¤†: " + e.message);
        }

        // 2. Microphone à¤®à¤¾à¤‚à¤—à¥‡à¤‚
        log("Requesting Mic...");
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        const source = audioContext.createMediaStreamSource(mediaStream);

        // 3. Worklet Node à¤¬à¤¨à¤¾à¤à¤
        workletNode = new AudioWorkletNode(audioContext, 'rnnoise-processor');
        
        // Processor à¤¸à¥‡ à¤®à¥ˆà¤¸à¥‡à¤œ à¤¸à¥à¤¨à¥‡à¤‚ (Debugging à¤•à¥‡ à¤²à¤¿à¤)
        workletNode.port.onmessage = (event) => {
            if (event.data.type === 'status') log("âœ… AI Active & Running!");
            if (event.data.type === 'error') log("âš ï¸ AI Error: " + event.data.message, true);
        };

        // 4. WASM à¤²à¥‹à¤¡ à¤•à¤°à¥‡à¤‚
        log("Fetching WASM...");
        const response = await fetch('rnnoise.wasm');
        if (!response.ok) throw new Error(`WASM à¤«à¤¾à¤‡à¤² à¤¨à¤¹à¥€à¤‚ à¤®à¤¿à¤²à¥€! (${response.status})`);
        
        const wasmBytes = await response.arrayBuffer();
        workletNode.port.postMessage({ type: 'load-wasm', wasmBytes });

        // 5. à¤•à¤¨à¥‡à¤•à¥à¤Ÿ à¤•à¤°à¥‡à¤‚
        const dest = audioContext.createMediaStreamDestination();
        source.connect(workletNode);
        workletNode.connect(dest);

        // 6. à¤°à¤¿à¤•à¥‰à¤°à¥à¤¡à¤°
        mediaRecorder = new MediaRecorder(dest.stream);
        mediaRecorder.ondataavailable = e => chunks.push(e.data);
        
        mediaRecorder.onstop = () => {
            const blob = new Blob(chunks, { type: 'audio/webm' });
            audioPlayer.src = URL.createObjectURL(blob);
            chunks = [];
            log("Recording Saved. Play ðŸ‘‡");
        };

        mediaRecorder.start();
        log("ðŸ”´ Recording... (Speak Now!)");
        
        startBtn.disabled = true;
        stopBtn.disabled = false;

    } catch (e) {
        log("âŒ Error: " + e.message, true);
    }
};

stopBtn.onclick = () => {
    if (mediaRecorder) mediaRecorder.stop();
    if (mediaStream) mediaStream.getTracks().forEach(track => track.stop());
    if (audioContext) audioContext.close();
    
    startBtn.disabled = false;
    stopBtn.disabled = true;
};
