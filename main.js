const startBtn = document.getElementById('btnStart');
const stopBtn = document.getElementById('btnStop');
const statusDiv = document.getElementById('status');
const timerDiv = document.getElementById('timer');
const canvas = document.getElementById('visualizer');
const audioPlayer = document.getElementById('audioPlayer');
const canvasCtx = canvas.getContext('2d');

let mediaRecorder;
let audioChunks = [];
let audioContext;
let analyser;
let source;

// Timer
let startTime;
let timerInterval;

function updateTimer() {
    const elapsed = Date.now() - startTime;
    const totalSeconds = Math.floor(elapsed / 1000);
    const minutes = Math.floor(totalSeconds / 60).toString().padStart(2, '0');
    const seconds = (totalSeconds % 60).toString().padStart(2, '0');
    timerDiv.innerText = `${minutes}:${seconds}`;
}

startBtn.onclick = async () => {
    try {
        statusDiv.innerText = "Initializing AI Logic...";
        
        startTime = Date.now();
        timerInterval = setInterval(updateTimer, 1000);
        timerDiv.style.color = "#ff3d00";

        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        await audioContext.resume();

        // 1. HARDWARE AI (Base Layer)
        // ‡§¨‡•ç‡§∞‡§æ‡§â‡•õ‡§∞ ‡§ï‡§æ ‡§Ö‡§™‡§®‡§æ AI ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§∂‡•ã‡§∞ ‡§ï‡•ã ‡§ï‡§Æ ‡§ï‡§∞‡•á‡§ó‡§æ
        const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                echoCancellation: true,
                noiseSuppression: true, // Krisp ‡§ú‡•à‡§∏‡§æ ‡§¨‡•á‡§∏‡§ø‡§ï AI
                autoGainControl: true,  // ‡§µ‡•â‡§≤‡•ç‡§Ø‡•Ç‡§Æ ‡§¨‡•à‡§≤‡•á‡§Ç‡§∏
                channelCount: 1
            }
        });

        source = audioContext.createMediaStreamSource(stream);

        // --- THE "KRISP" STRATEGY (Multi-Stage Isolation) ---
        // ‡§π‡§Æ ‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•ã ‡§§‡§∞‡§æ‡§∂‡•á‡§Ç‡§ó‡•á (Sculpting), ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§ï‡§æ‡§ü‡•á‡§Ç‡§ó‡•á ‡§®‡§π‡•Ä‡§Ç‡•§

        // STAGE 1: BRICK WALL FILTERS (‡§´‡§æ‡§≤‡§§‡•Ç ‡§´‡•ç‡§∞‡•Ä‡§ï‡•ç‡§µ‡•á‡§Ç‡§∏‡•Ä ‡§¨‡§æ‡§π‡§∞)
        
        // A. Rumble Wall (150Hz) - ‡§™‡§Ç‡§ñ‡§æ/‡§á‡§Ç‡§ú‡§® ‡§ñ‡§§‡•ç‡§Æ
        const lowCut = audioContext.createBiquadFilter();
        lowCut.type = 'highpass';
        lowCut.frequency.value = 150; 
        lowCut.Q.value = 1.0; // Sharpness

        // B. Hiss Wall (3500Hz) - ‡§π‡•â‡§∞‡•ç‡§®/‡§∏‡•Ä‡§ü‡•Ä ‡§ñ‡§§‡•ç‡§Æ
        // ‡§á‡§Ç‡§∏‡§æ‡§® ‡§ï‡•Ä ‡§∏‡§æ‡•û ‡§Ü‡§µ‡§æ‡•õ 3000-3500Hz ‡§§‡§ï ‡§π‡•Ä ‡§π‡•ã‡§§‡•Ä ‡§π‡•à‡•§
        const highCut = audioContext.createBiquadFilter();
        highCut.type = 'lowpass';
        highCut.frequency.value = 3500; 
        highCut.Q.value = 1.0;

        // STAGE 2: VOCAL ENHANCEMENT (‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•ã ‡§∏‡§æ‡•û ‡§ï‡§∞‡§®‡§æ)
        
        // C. Mud Remover (300Hz) - ‡§ó‡•Ç‡§Ç‡§ú ‡§π‡§ü‡§æ‡§®‡§æ
        const mudCut = audioContext.createBiquadFilter();
        mudCut.type = 'peaking';
        mudCut.frequency.value = 300;
        mudCut.gain.value = -10; // -10dB

        // D. Clarity Boost (2000Hz) - ‡§Ü‡§µ‡§æ‡•õ ‡§Æ‡•á‡§Ç ‡§ö‡§Æ‡§ï ‡§≤‡§æ‡§®‡§æ
        const clarityBoost = audioContext.createBiquadFilter();
        clarityBoost.type = 'peaking';
        clarityBoost.frequency.value = 2000;
        clarityBoost.gain.value = 5; // +5dB

        // STAGE 3: DYNAMICS PROCESSING (Noise Gate + Compressor)
        
        // E. Compressor (‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•ã ‡§è‡§ï ‡§≤‡•á‡§µ‡§≤ ‡§™‡§∞ ‡§∞‡§ñ‡§®‡§æ)
        const compressor = audioContext.createDynamicsCompressor();
        compressor.threshold.value = -24;
        compressor.knee.value = 20;
        compressor.ratio.value = 5;
        compressor.attack.value = 0.005;
        compressor.release.value = 0.20;

        // F. EXPANDER / GATE (‡§∏‡§®‡•ç‡§®‡§æ‡§ü‡§æ ‡§ï‡§∞‡§®‡§æ)
        // ‡§Ø‡§π Krisp ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§π‡§Æ ‡§π‡§ø‡§∏‡•ç‡§∏‡§æ ‡§π‡•à‡•§ ‡§ú‡§¨ ‡§Ü‡§™ ‡§ö‡•Å‡§™ ‡§π‡•ã‡§Ç, ‡§Ø‡§π ‡§Æ‡§æ‡§á‡§ï ‡§¨‡§Ç‡§¶ ‡§ï‡§∞ ‡§¶‡•á‡§ó‡§æ‡•§
        const scriptNode = audioContext.createScriptProcessor(4096, 1, 1);
        
        // Settings for Gate
        const NOISE_FLOOR = 0.04; // 4% ‡§∏‡•á ‡§®‡•Ä‡§ö‡•á ‡§∂‡•ã‡§∞ ‡§Æ‡§æ‡§®‡§æ ‡§ú‡§æ‡§è‡§ó‡§æ
        let envelope = 0;

        scriptNode.onaudioprocess = function(ev) {
            const input = ev.inputBuffer.getChannelData(0);
            const output = ev.outputBuffer.getChannelData(0);

            for (let i = 0; i < input.length; i++) {
                const sample = input[i];
                const amplitude = Math.abs(sample);

                // Smooth Envelope Follower (‡§Ü‡§µ‡§æ‡•õ ‡§ï‡§æ ‡§™‡•Ä‡§õ‡§æ ‡§ï‡§∞‡§®‡§æ)
                if (amplitude > envelope) {
                    envelope = 0.001 * (amplitude - envelope) + envelope;
                } else {
                    envelope = 0.0001 * (amplitude - envelope) + envelope;
                }

                // SMART GATE LOGIC
                if (envelope < NOISE_FLOOR) {
                    // ‡§Ö‡§ó‡§∞ ‡§∂‡•ã‡§∞ ‡§π‡•à, ‡§§‡•ã ‡§ß‡•Ä‡§∞‡•á-‡§ß‡•Ä‡§∞‡•á ‡§Ü‡§µ‡§æ‡•õ ‡§ï‡§Æ ‡§ï‡§∞‡•ã (Fade Out)
                    // ‡§∏‡•Ä‡§ß‡§æ 0 ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á ‡§µ‡§∞‡§®‡§æ ‡§Ü‡§µ‡§æ‡•õ ‡§ï‡§ü‡•á‡§ó‡•Ä
                    output[i] = sample * 0.1; 
                } else {
                    // ‡§Ö‡§ó‡§∞ ‡§Ü‡§µ‡§æ‡•õ ‡§π‡•à, ‡§§‡•ã ‡§™‡•Ç‡§∞‡•Ä ‡§ú‡§æ‡§®‡•á ‡§¶‡•ã
                    output[i] = sample;
                }
            }
        };

        // CONNECTIONS (The Chain)
        // Source -> LowCut -> HighCut -> MudCut -> Clarity -> Compressor -> Gate -> Out
        source.connect(lowCut);
        lowCut.connect(highCut);
        highCut.connect(mudCut);
        mudCut.connect(clarityBoost);
        clarityBoost.connect(compressor);
        compressor.connect(scriptNode);
        
        // Visualizer
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        scriptNode.connect(analyser);

        const dest = audioContext.createMediaStreamDestination();
        scriptNode.connect(dest);

        // RECORDER
        let options = { mimeType: 'audio/webm;codecs=opus' };
        if (!MediaRecorder.isTypeSupported(options.mimeType)) { options = { mimeType: 'audio/mp4' }; }

        mediaRecorder = new MediaRecorder(dest.stream, options);

        mediaRecorder.ondataavailable = (e) => {
            if (e.data.size > 0) audioChunks.push(e.data);
        };

        mediaRecorder.onstop = () => {
            const blob = new Blob(audioChunks, { type: 'audio/webm' });
            const url = URL.createObjectURL(blob);
            audioPlayer.src = url;
            audioPlayer.style.display = 'block';
            audioChunks = [];
            statusDiv.innerText = "‚úÖ Saved (Voice Only)!";
            statusDiv.style.color = "#00e676";
            timerDiv.style.color = "#00e676";
        };

        mediaRecorder.start();
        visualize();

        // UI
        startBtn.disabled = true;
        startBtn.style.opacity = "0.5";
        stopBtn.disabled = false;
        stopBtn.style.opacity = "1";
        stopBtn.style.pointerEvents = "all";
        stopBtn.style.background = "#ff3d00";
        statusDiv.innerText = "üî¥ Recording (Vocal Isolation)...";
        statusDiv.style.color = "#ff3d00";

    } catch (err) {
        clearInterval(timerInterval);
        statusDiv.innerText = "Error: " + err.message;
        statusDiv.style.color = "red";
    }
};

stopBtn.onclick = () => {
    clearInterval(timerInterval);
    if (mediaRecorder) mediaRecorder.stop();
    if (source) source.mediaStream.getTracks().forEach(t => t.stop());
    if (audioContext) audioContext.close();
    
    startBtn.disabled = false;
    startBtn.style.opacity = "1";
    stopBtn.disabled = true;
    stopBtn.style.opacity = "0.5";
    stopBtn.style.pointerEvents = "none";
    if(drawVisual) cancelAnimationFrame(drawVisual);
};

// Visualizer
let drawVisual;
function visualize() {
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    const draw = () => {
        if(!startBtn.disabled) return;
        requestAnimationFrame(draw);
        analyser.getByteFrequencyData(dataArray);
        canvasCtx.fillStyle = '#000';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
        let x = 0;
        let barWidth = (canvas.width / bufferLength) * 2.5;
        for (let i = 0; i < bufferLength; i++) {
            let barHeight = dataArray[i] / 2;
            canvasCtx.fillStyle = `hsl(${barHeight + 160},100%,50%)`; // Aqua Blue
            canvasCtx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight);
            x += barWidth + 1;
        }
    };
    draw();
}
